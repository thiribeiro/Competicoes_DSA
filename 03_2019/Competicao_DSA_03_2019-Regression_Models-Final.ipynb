{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.mribeiro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Pegando arquivos .csv \n",
    "df = pd.read_csv('dataset_ajust_train.csv',sep=',', encoding='ISO-8859-1')\n",
    "dfTest = pd.read_csv('dataset_ajust_test.csv',sep=',', encoding='ISO-8859-1')\n",
    "#dfLojas = pd.read_csv('lojas.csv',sep=',', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiago.mribeiro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.         1.         0.54545455 1.\n",
      "  1.         1.         0.         0.         0.         0.\n",
      "  1.         0.         0.         1.         0.         1.        ]\n",
      " [1.         1.         1.         1.         0.54545455 0.96666667\n",
      "  0.9989373  0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         1.         0.         1.        ]\n",
      " [1.         1.         1.         1.         0.54545455 0.93333333\n",
      "  0.9978746  0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         1.         0.         1.        ]\n",
      " [1.         1.         1.         1.         0.54545455 0.9\n",
      "  0.9968119  0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.         1.        ]\n",
      " [1.         1.         1.         1.         0.54545455 0.86666667\n",
      "  0.9957492  0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         1.        ]]\n",
      "[[1.         1.         0.         0.         1.         0.53333333\n",
      "  1.         0.         0.         0.         0.         1.\n",
      "  0.         0.         0.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.         1.         0.5\n",
      "  0.9787234  0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.         1.         0.46666667\n",
      "  0.95744681 0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.        ]\n",
      " [1.         1.         0.         0.         1.         0.43333333\n",
      "  0.93617021 0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.        ]\n",
      " [0.         0.         0.         0.         1.         0.4\n",
      "  0.91489362 1.         0.         0.         0.         0.\n",
      "  0.         0.         1.         1.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Colocando os Dados na mesma escala\n",
    "\n",
    "#=========== Modelo com todas as variaveis (dfAjustado)=========================================\n",
    "#colsDFSel = ['Open', 'Promo', 'SchoolHoliday', 'Year', 'Month', 'Day',\n",
    "#       'DayOfWeek_1', 'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4',\n",
    "#       'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7', 'StateHoliday_0',\n",
    "#       'StateHoliday_a', 'Sales']\n",
    "\n",
    "#colsDFSELTest = ['Open', 'Promo', 'SchoolHoliday', 'Year', 'Month', 'Day', 'DayOfWeek_1',\n",
    "#       'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5',\n",
    "#       'DayOfWeek_6', 'DayOfWeek_7', 'StateHoliday_0', 'StateHoliday_a']\n",
    "\n",
    "\n",
    "#Melhores resultados até o momento\n",
    "colsDFSel = ['Open', 'Promo', 'SchoolHoliday', 'Year', 'Month', 'Day',\n",
    "       'DaysSinceBeginning', 'Weekend', 'DayOfWeek_1', 'DayOfWeek_2',\n",
    "       'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6',\n",
    "       'DayOfWeek_7', 'StateHoliday_0', 'StateHoliday_a', 'Quarter_3', 'Sales']\n",
    "\n",
    "             \n",
    "colsDFSELTest = ['Open', 'Promo', 'SchoolHoliday', 'Year', 'Month', 'Day',\n",
    "       'DaysSinceBeginning', 'Weekend', 'DayOfWeek_1', 'DayOfWeek_2',\n",
    "       'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5', 'DayOfWeek_6',\n",
    "       'DayOfWeek_7', 'StateHoliday_0', 'StateHoliday_a', 'Quarter_3']\n",
    " \n",
    "    \n",
    "#===============================================================================================\n",
    "\n",
    "#========== Modelo com as variaveis selecionadas pelo RandomForest(dfAjustado) =================\n",
    "#colsDFSel = ['Open','Month', 'Day','StateHoliday_0','StateHoliday_a', 'Sales']\n",
    "#colsDFSELTest = ['Open','Month', 'Day','StateHoliday_0','StateHoliday_a']\n",
    "\n",
    "#colsDFSel = ['Open', 'Promo', 'SchoolHoliday', 'Month', 'Day',\n",
    "#       'DayOfWeek_1', 'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4',\n",
    "#       'DayOfWeek_5', 'DayOfWeek_6', 'StateHoliday_0',\n",
    "#       'StateHoliday_a', 'Sales']\n",
    "\n",
    "#colsDFSELTest = ['Open', 'Promo', 'SchoolHoliday', 'Month', 'Day', 'DayOfWeek_1',\n",
    "#       'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5',\n",
    "#       'DayOfWeek_6', 'StateHoliday_0', 'StateHoliday_a']\n",
    "\n",
    "#===============================================================================================\n",
    "\n",
    "\n",
    "colTrain = colsDFSel\n",
    "#dfMLTrain = dfAjustado[colTrain]\n",
    "dfMLTrain = dfTudo[colTrain]\n",
    "arrayTrain = dfMLTrain.values\n",
    "\n",
    "#Fazendo split nos dados de treino\n",
    "XTrain = arrayTrain[:,0:18]\n",
    "YTrain = arrayTrain[:,18]\n",
    "\n",
    "#Criando escala\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "rescaledXTrain = scaler.fit_transform(XTrain)\n",
    "\n",
    "#Dados na escala\n",
    "print(rescaledXTrain[0:5,:])\n",
    "\n",
    "\n",
    "#================ TESTE ==========================\n",
    "colTest = colsDFSELTest\n",
    "#dfMLTest = dfAjustadoTest[colTest]\n",
    "dfMLTest = dfTudoTest[colTest]\n",
    "arrayTest = dfMLTest.values\n",
    "XTEST = arrayTest[:,0:18]\n",
    "#YTEST = arrayTrain[:,14]\n",
    "rescaledXTest = scaler.fit_transform(XTEST)\n",
    "print(rescaledXTest[0:5,:])\n",
    "#=================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo os dados de treino com train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(rescaledXTrain, YTrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSMPE\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "def resultado_rsmpe(y, yhat):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5512677614875545\n",
      "Accuracy: 0.55 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import cross_validate as cv\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#dfTudo todas as variaveis\n",
    "#0.5802462132322554\n",
    "\n",
    "#dfAjustado ==> variaveis novas\n",
    "#0.55136\n",
    "\n",
    "\n",
    "modelLR = LinearRegression()\n",
    "kfolds = KFold(n_splits=40, shuffle=True, random_state=42)\n",
    "\n",
    "#Testando e usando os dados de Treino(sem split)\n",
    "#scores = cross_val_score(modelLR,rescaledXTrain, YTrain, cv=kfolds)\n",
    "#modelLR.fit(rescaledXTrain, YTrain)\n",
    "#print(modelLR.score(rescaledXTrain, YTrain))\n",
    "\n",
    "\n",
    "#Testando com os proprios dados de treino(com split)\n",
    "scores = cross_val_score(modelLR, X_train, y_train, cv=kfolds)\n",
    "modelLR.fit(X_train, y_train)\n",
    "print(modelLR.score(X_train, y_train))\n",
    "\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "#YPredLR = modelLR.predict(X_test)\n",
    "YPredLR = modelLR.predict(rescaledXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47714553877962074\n"
     ]
    }
   ],
   "source": [
    "#res = resultado_rsmpe(y_train, YPredLR)\n",
    "YPredLR_2 = modelLR.predict(rescaledXTrain)\n",
    "res = resultado_rsmpe(YTrain, YPredLR_2)\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.39\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#dfAjustado\n",
    "#{'loss': 'ls', 'n_estimators': 100}\n",
    "#51.61\n",
    "#{'loss': 'ls', 'n_estimators': 100} ====> abordagem 3\n",
    "#58.17\n",
    "\n",
    "#dfAjustado ====> variaveis novas\n",
    "#(n_estimators=100, loss='huber', random_state=42)\n",
    "#57.68\n",
    "\n",
    "modelGBR = GradientBoostingRegressor(n_estimators=100, loss='ls', random_state=42)\n",
    "modelGBR.fit(rescaledXTrain, YTrain)\n",
    "print(round(modelGBR.score(rescaledXTrain, YTrain) * 100, 2))\n",
    "\n",
    "# Predictions\n",
    "YPredGBR = modelGBR.predict(rescaledXTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4676810247755273\n"
     ]
    }
   ],
   "source": [
    "YPredGBR_2 = modelGBR.predict(X_train)\n",
    "res3 = resultado_rsmpe(y_train, YPredGBR_2)\n",
    "print (res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gerando o resultado para o Submission File\n",
    "#resultado = np.around(YPredLR, decimals=2)\n",
    "#resultado = np.around(YPredGBR, decimals=2)\n",
    "resultado = [ int(x) for x in YPredGBR ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Submission file\n",
    "submission = pd.DataFrame({\n",
    "        \"ID\": dfTest['Id'],\n",
    "        \"Sales\": resultado\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
